[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "gymnasium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gymnasium",
        "description": "gymnasium",
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "optimizers",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "losses",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "keras",
        "description": "keras",
        "isExtraImport": true,
        "detail": "keras",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pygame",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pygame",
        "description": "pygame",
        "detail": "pygame",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "importPath": "dqn_agent",
        "description": "dqn_agent",
        "isExtraImport": true,
        "detail": "dqn_agent",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "importPath": "dqn_agent",
        "description": "dqn_agent",
        "isExtraImport": true,
        "detail": "dqn_agent",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "keras",
        "importPath": "tensorflow",
        "description": "tensorflow",
        "isExtraImport": true,
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "visualize_rewards",
        "kind": 2,
        "importPath": "cartpole_plot_rewards",
        "description": "cartpole_plot_rewards",
        "peekOfCode": "def visualize_rewards():\n    # Load rewards per episode from the saved file\n    rewards_per_episode = np.load('dqn_cartpole.keras_rewards_per_episode.npy')\n    EPISODES = len(rewards_per_episode)\n    # Plot the total rewards per episode\n    plt.figure(figsize=(12, 6))\n    plt.plot(range(1, EPISODES + 1), rewards_per_episode)\n    plt.xlabel('Episode')\n    plt.ylabel('Total Reward')\n    plt.title('Agent Performance over Episodes during Training')",
        "detail": "cartpole_plot_rewards",
        "documentation": {}
    },
    {
        "label": "run_agent",
        "kind": 2,
        "importPath": "cartpole_test",
        "description": "cartpole_test",
        "peekOfCode": "def run_agent():\n    # Load the trained model\n    model_path = 'dqn_cartpole.keras'\n    if os.path.exists(model_path):\n        model = models.load_model(model_path)\n        print(f\"Loaded model from {model_path}\")\n    else:\n        print(\"Trained model not found.\")\n        return\n    # Create the environment",
        "detail": "cartpole_test",
        "documentation": {}
    },
    {
        "label": "train_dqn",
        "kind": 2,
        "importPath": "cartpole_train",
        "description": "cartpole_train",
        "peekOfCode": "def train_dqn(continue_training=False):\n    env = gym.make('CartPole-v1')\n    state_size = env.observation_space.shape[0]\n    action_size = env.action_space.n\n    model_path = \"dqn_cartpole.keras\"\n    # Extract base name without extension from model_path for dynamic rewards file\n    rewards_file = model_path + \"_rewards_per_episode.npy\"\n    # Initialize the DQNAgent with dynamic model path\n    agent = DQNAgent(state_size, action_size, model_path, load_model=continue_training)\n    batch_size = 32",
        "detail": "cartpole_train",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "kind": 6,
        "importPath": "dqn_agent",
        "description": "dqn_agent",
        "peekOfCode": "class DQNAgent:\n    def __init__(self, state_size, action_size, model_path, load_model=False):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.model_path = model_path\n        self.memory = deque(maxlen=5000)\n        self.gamma = 0.95  # Discount factor\n        self.epsilon = 1.0  # Exploration rate\n        self.epsilon_min = 0.01\n        self.epsilon_decay = 0.995",
        "detail": "dqn_agent",
        "documentation": {}
    },
    {
        "label": "visualize_rewards",
        "kind": 2,
        "importPath": "mountain_car_plot_rewards",
        "description": "mountain_car_plot_rewards",
        "peekOfCode": "def visualize_rewards():\n    # Load rewards per episode from the saved file\n    rewards_per_episode = np.load('dqn_mountain_car.keras_rewards_per_episode.npy')\n    EPISODES = len(rewards_per_episode)\n    # Plot the total rewards per episode\n    plt.figure(figsize=(12, 6))\n    plt.plot(range(1, EPISODES + 1), rewards_per_episode)\n    plt.xlabel('Episode')\n    plt.ylabel('Total Reward')\n    plt.title('Agent Performance over Episodes during Training')",
        "detail": "mountain_car_plot_rewards",
        "documentation": {}
    },
    {
        "label": "run_agent",
        "kind": 2,
        "importPath": "mountain_car_test",
        "description": "mountain_car_test",
        "peekOfCode": "def run_agent():\n    # Load the trained model\n    model_path = 'dqn_mountain_car.keras'\n    if os.path.exists(model_path):\n        model = models.load_model(model_path)\n        print(f\"Loaded model from {model_path}\")\n    else:\n        print(\"Trained model not found.\")\n        return\n    # Create the environment",
        "detail": "mountain_car_test",
        "documentation": {}
    },
    {
        "label": "run_episode",
        "kind": 2,
        "importPath": "mountain_train",
        "description": "mountain_train",
        "peekOfCode": "def run_episode(agent, env, train=True, batch_size=64, max_steps=200):\n    total_reward = 0\n    state, _ = env.reset()  # Reset environment and get the initial state\n    state = state.reshape(1, -1)  # Ensure state is in the right shape\n    terminated = False\n    steps = 0\n    highest_peak = state[0, 0]  # Track the highest position reached in the episode\n    while not terminated and steps < max_steps:\n        # Select an action using the DQN agent\n        action = agent.act(state)",
        "detail": "mountain_train",
        "documentation": {}
    },
    {
        "label": "train_dqn_mountain_car",
        "kind": 2,
        "importPath": "mountain_train",
        "description": "mountain_train",
        "peekOfCode": "def train_dqn_mountain_car(episodes, render=False):\n    model_path = \"dqn_mountain_car.keras\"\n    rewards_file = model_path + \"_rewards_per_episode.npy\"\n    continue_training = os.path.exists(model_path) and os.path.exists(rewards_file)\n    if continue_training:\n        rewards_per_episode = np.load(rewards_file).tolist()\n        start_episode = len(rewards_per_episode)\n        print(f\"Continuing training from episode {start_episode}\")\n    else:\n        rewards_per_episode = []",
        "detail": "mountain_train",
        "documentation": {}
    }
]