[
    {
        "label": "gymnasium",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gymnasium",
        "description": "gymnasium",
        "detail": "gymnasium",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "optimizers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "gym",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gym",
        "description": "gym",
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "kind": 6,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "class DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate\n        self.epsilon_min = 0.01     # Minimum exploration rate\n        self.epsilon_decay = 0.995  # Exploration decay rate\n        self.learning_rate = 0.001",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "env_name",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "env_name = 'CartPole-v1'\nenv = gym.make(env_name)\nstate_size = env.observation_space.shape[0]  # Should be 4\naction_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "env = gym.make(env_name)\nstate_size = env.observation_space.shape[0]  # Should be 4\naction_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "state_size",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "state_size = env.observation_space.shape[0]  # Should be 4\naction_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "action_size",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "action_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate\n        self.epsilon_min = 0.01     # Minimum exploration rate",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "load_model = True  # Set to True to load a model, False to train a new one\n# Training parameters\nepisodes = 1000\noutput_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\nagent = DQNAgent(state_size, action_size)\nif load_model:\n    # Load the trained model\n    checkpoint_name = output_dir + 'checkpoint'",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "episodes",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "episodes = 1000\noutput_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\nagent = DQNAgent(state_size, action_size)\nif load_model:\n    # Load the trained model\n    checkpoint_name = output_dir + 'checkpoint'\n    if os.path.isfile(checkpoint_name + '_model.h5'):\n        agent.load(checkpoint_name)",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "output_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\nagent = DQNAgent(state_size, action_size)\nif load_model:\n    # Load the trained model\n    checkpoint_name = output_dir + 'checkpoint'\n    if os.path.isfile(checkpoint_name + '_model.h5'):\n        agent.load(checkpoint_name)\n        print(\"Loaded model from checkpoint.\")",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "agent",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "agent = DQNAgent(state_size, action_size)\nif load_model:\n    # Load the trained model\n    checkpoint_name = output_dir + 'checkpoint'\n    if os.path.isfile(checkpoint_name + '_model.h5'):\n        agent.load(checkpoint_name)\n        print(\"Loaded model from checkpoint.\")\n    else:\n        print(\"No saved model found at checkpoint. Starting training a new model.\")\n        load_model = False",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "rewards_list",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "rewards_list = []\nif not load_model:\n    # Training loop\n    for e in range(episodes):\n        state, _ = env.reset()\n        state = np.reshape(state, [1, state_size])\n        total_reward = 0\n        for time in range(500):\n            action = agent.act(state)\n            next_state, reward, terminated, truncated, _ = env.step(action)",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "env = gym.make(env_name, render_mode='human')\nfor e in range(5):\n    state, _ = env.reset()\n    state = np.reshape(state, [1, state_size])\n    total_reward = 0\n    for time in range(500):\n        env.render()\n        action = np.argmax(agent.model.predict(state, verbose=0)[0])\n        next_state, reward, terminated, truncated, _ = env.step(action)\n        done = terminated or truncated",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "kind": 6,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "class DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size\n        self.memory = deque(maxlen=MEMORY_SIZE)\n        self.epsilon = EPSILON_START\n        print(\"[DEBUG] Initializing DQN agent with action size:\", action_size)\n        self.model = self.build_model()\n        self.target_model = self.build_model()\n        self.update_target_model()\n        print(\"[DEBUG] DQN agent initialized successfully.\")",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "preprocess_frame",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size\n        self.memory = deque(maxlen=MEMORY_SIZE)\n        self.epsilon = EPSILON_START",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def train_agent(env):\n    agent = DQNAgent(action_size=env.action_space.n)\n    scores = []\n    for e in range(TRAINING_EPISODES):\n        print(f\"\\n[DEBUG] Starting episode {e+1}/{TRAINING_EPISODES}\")\n        state = preprocess_frame(env.reset())\n        state = np.stack([state] * 4, axis=2)  # Stack 4 frames\n        total_reward = 0\n        for time in range(MAX_STEPS_PER_EPISODE):\n            action = agent.act(state)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "render_game",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def render_game(agent, env):\n    print(\"[DEBUG] Starting game rendering.\")\n    state = preprocess_frame(env.reset())\n    state = np.stack([state] * 4, axis=2)\n    for _ in range(MAX_STEPS_PER_EPISODE):\n        action = agent.act(state)\n        next_frame, _, done, _ = env.step(action)\n        env.render()  # Display the game\n        next_state = preprocess_frame(next_frame)\n        next_state = np.stack([next_state] * 4, axis=2)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "MEMORY_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "MEMORY_SIZE = 10000\nBATCH_SIZE = 32\nGAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "BATCH_SIZE = 32\nGAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "GAMMA",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "GAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_START",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_END",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_DECAY",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "TARGET_UPDATE_FREQUENCY",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "TARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "TRAINING_EPISODES",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "TRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "MAX_STEPS_PER_EPISODE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "MAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "REPLAY_START_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "REPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "LEARNING_RATE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "LEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size",
        "detail": "test",
        "documentation": {}
    }
]