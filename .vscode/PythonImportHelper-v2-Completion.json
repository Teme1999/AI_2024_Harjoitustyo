[
    {
        "label": "gym",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gym",
        "description": "gym",
        "detail": "gym",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "optimizers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "deque",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "Display",
        "importPath": "pyvirtualdisplay",
        "description": "pyvirtualdisplay",
        "isExtraImport": true,
        "detail": "pyvirtualdisplay",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "kind": 6,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "class DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate\n        self.epsilon_min = 0.01     # Minimum exploration rate\n        self.epsilon_decay = 0.995  # Exploration decay rate\n        self.learning_rate = 0.001",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "env",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "env = gym.make('CartPole-v1')\nstate_size = env.observation_space.shape[0]  # Should be 4\naction_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "state_size",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "state_size = env.observation_space.shape[0]  # Should be 4\naction_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "action_size",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "action_size = env.action_space.n  # Should be 2\n# Define the DQNAgent class\nclass DQNAgent:\n    def __init__(self, state_size, action_size):\n        self.state_size = state_size\n        self.action_size = action_size\n        # Hyperparameters\n        self.gamma = 0.95           # Discount factor\n        self.epsilon = 1.0          # Exploration rate\n        self.epsilon_min = 0.01     # Minimum exploration rate",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "agent",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "agent = DQNAgent(state_size, action_size)\n# Training parameters\nepisodes = 1000\noutput_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n# To store rewards for visualization\nrewards_list = []\n# Load previous training state if available\nresume_training = True  # Set to True if you want to resume training",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "episodes",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "episodes = 1000\noutput_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n# To store rewards for visualization\nrewards_list = []\n# Load previous training state if available\nresume_training = True  # Set to True if you want to resume training\ncheckpoint_name = output_dir + 'checkpoint'\nif resume_training and os.path.isfile(checkpoint_name + '_model.h5'):",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "output_dir",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "output_dir = 'model_output/cartpole_dqn/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n# To store rewards for visualization\nrewards_list = []\n# Load previous training state if available\nresume_training = True  # Set to True if you want to resume training\ncheckpoint_name = output_dir + 'checkpoint'\nif resume_training and os.path.isfile(checkpoint_name + '_model.h5'):\n    agent.load(checkpoint_name)",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "rewards_list",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "rewards_list = []\n# Load previous training state if available\nresume_training = True  # Set to True if you want to resume training\ncheckpoint_name = output_dir + 'checkpoint'\nif resume_training and os.path.isfile(checkpoint_name + '_model.h5'):\n    agent.load(checkpoint_name)\n    with open(output_dir + 'rewards_list.pkl', 'rb') as f:\n        rewards_list = pickle.load(f)\n    starting_episode = len(rewards_list)\n    print(f\"Resuming training from episode {starting_episode}\")",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "resume_training",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "resume_training = True  # Set to True if you want to resume training\ncheckpoint_name = output_dir + 'checkpoint'\nif resume_training and os.path.isfile(checkpoint_name + '_model.h5'):\n    agent.load(checkpoint_name)\n    with open(output_dir + 'rewards_list.pkl', 'rb') as f:\n        rewards_list = pickle.load(f)\n    starting_episode = len(rewards_list)\n    print(f\"Resuming training from episode {starting_episode}\")\nelse:\n    starting_episode = 0",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "checkpoint_name",
        "kind": 5,
        "importPath": "cartpole",
        "description": "cartpole",
        "peekOfCode": "checkpoint_name = output_dir + 'checkpoint'\nif resume_training and os.path.isfile(checkpoint_name + '_model.h5'):\n    agent.load(checkpoint_name)\n    with open(output_dir + 'rewards_list.pkl', 'rb') as f:\n        rewards_list = pickle.load(f)\n    starting_episode = len(rewards_list)\n    print(f\"Resuming training from episode {starting_episode}\")\nelse:\n    starting_episode = 0\n# Training loop",
        "detail": "cartpole",
        "documentation": {}
    },
    {
        "label": "DQNAgent",
        "kind": 6,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "class DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size\n        self.memory = deque(maxlen=MEMORY_SIZE)\n        self.epsilon = EPSILON_START\n        print(\"[DEBUG] Initializing DQN agent with action size:\", action_size)\n        self.model = self.build_model()\n        self.target_model = self.build_model()\n        self.update_target_model()\n        print(\"[DEBUG] DQN agent initialized successfully.\")",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "preprocess_frame",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size\n        self.memory = deque(maxlen=MEMORY_SIZE)\n        self.epsilon = EPSILON_START",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "train_agent",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def train_agent(env):\n    agent = DQNAgent(action_size=env.action_space.n)\n    scores = []\n    for e in range(TRAINING_EPISODES):\n        print(f\"\\n[DEBUG] Starting episode {e+1}/{TRAINING_EPISODES}\")\n        state = preprocess_frame(env.reset())\n        state = np.stack([state] * 4, axis=2)  # Stack 4 frames\n        total_reward = 0\n        for time in range(MAX_STEPS_PER_EPISODE):\n            action = agent.act(state)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "render_game",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def render_game(agent, env):\n    print(\"[DEBUG] Starting game rendering.\")\n    state = preprocess_frame(env.reset())\n    state = np.stack([state] * 4, axis=2)\n    for _ in range(MAX_STEPS_PER_EPISODE):\n        action = agent.act(state)\n        next_frame, _, done, _ = env.step(action)\n        env.render()  # Display the game\n        next_state = preprocess_frame(next_frame)\n        next_state = np.stack([next_state] * 4, axis=2)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "MEMORY_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "MEMORY_SIZE = 10000\nBATCH_SIZE = 32\nGAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "BATCH_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "BATCH_SIZE = 32\nGAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "GAMMA",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "GAMMA = 0.99\nEPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_START",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_START = 1.0\nEPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_END",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_END = 0.1\nEPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "EPSILON_DECAY",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "EPSILON_DECAY = 1000000\nTARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "TARGET_UPDATE_FREQUENCY",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "TARGET_UPDATE_FREQUENCY = 1000\nTRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "TRAINING_EPISODES",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "TRAINING_EPISODES = 10000\nMAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "MAX_STEPS_PER_EPISODE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "MAX_STEPS_PER_EPISODE = 500\nREPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "REPLAY_START_SIZE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "REPLAY_START_SIZE = 1000\nLEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "LEARNING_RATE",
        "kind": 5,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "LEARNING_RATE = 0.00025\n# Preprocess frames to grayscale and resize\ndef preprocess_frame(frame):\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized_frame = cv2.resize(gray_frame, (84, 84), interpolation=cv2.INTER_AREA)\n    return resized_frame / 255.0\n# Deep Q-Network with Debugging Prints\nclass DQNAgent:\n    def __init__(self, action_size):\n        self.action_size = action_size",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "test2",
        "description": "test2",
        "peekOfCode": "start_time = time.time()\ntry:\n    print(\"Initializing Display object...\")\n    display = Display(visible=0, size=(1400, 900))\n    print(\"Starting Display...\")\n    display.start()\n    print(\"Virtual display started.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n# End the timer and print the elapsed time",
        "detail": "test2",
        "documentation": {}
    },
    {
        "label": "end_time",
        "kind": 5,
        "importPath": "test2",
        "description": "test2",
        "peekOfCode": "end_time = time.time()\nprint(f\"Virtual display setup completed in {end_time - start_time:.2f} seconds.\")",
        "detail": "test2",
        "documentation": {}
    }
]